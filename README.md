# Requirements
- Docker and Docker Compose
- Ollama installed on the host machine
- DeepSeek R1 1.5b (or later) installed via Ollama

## Installation
1. Clone the repository:
```bash
git clone https://github.com/tuouser/doc-analyzer
cd doc-analyzer
```
2. Create the .env file from the example configuration:
```bash
cp .env.example .env
```
3. Build the application:
```
docker-compose build
```
4. Start the application:
```bash
docker-compose up -d
```
5. Access the web interface at:
```
http://localhost:8000
```

## Usage
1. Upload a PDF file through the web interface
2. Ask a question about the document content
3. Receive a response generated by DeepSeek R1 based on the document content

## Project Structure
```
doc-analyzer/
├── src/
│   ├── app.py
├── .env.example
├── Dockerfile
│    docker-compose.yml
├── requirements.txt
└── README.md
```

## How It Works
1. The PDF is uploaded and processed into chunks
2. Chunks are converted into embeddings using DeepSeek
3. Embeddings are saved in ChromaDB
4. Queries are processed using a RAG system
5. DeepSeek generates responses based on the most relevant chunks

## Development
To develop using Docker:
```bash
# Build the Docker image
docker-compose build

# Start the development containers
docker-compose up -d

# View logs
docker-compose logs -f

# Stop the containers
docker-compose down
```

## Local Development (without Docker)
If you prefer to run the application locally:
```bash
# Create a virtual environment
python -m venv venv
source venv/bin/activate  # or .\venv\Scripts\activate on Windows

# Install dependencies
pip install -r requirements.txt

# Start the application
uvicorn src.app:app --reload
```

## License
MIT

## Contributing
Contributions are welcome! Please:
1. Fork the repository
2. Create a branch for your feature
3. Commit your changes
4. Push to the branch
5. Open a Pull Request
